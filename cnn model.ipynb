{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e03dde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all necessary libraries for the program\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.regularizers import L2\n",
    "import time\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff15b291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definig some variables\n",
    "IMG_SIZE = 50\n",
    "\n",
    "# note: the training and testing set \n",
    "#should be in this folder to run the program correctly\n",
    "\n",
    "DATADIR = \"C:/Assignment_images\"  \n",
    "test_dir = \"C:/test_set\"\n",
    "CATEGORIES = [\"cats\", \"dogs\"]\n",
    "NAME = f\"cats-vs-dogs-cnn-64x2-{int(time.time())}\"\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=f\"logs/{NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "598ab05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a training data set\n",
    "training_data = []\n",
    "def create_training_data():\n",
    "    for category in CATEGORIES:\n",
    "        path = os.path.join(DATADIR, category) # path to cats or dogs directory\n",
    "        class_num = CATEGORIES.index(category)\n",
    "        \n",
    "        for img in os.listdir(path):\n",
    "            # using try and except to pass all the images that have problem in resizeing\n",
    "            try: \n",
    "                img_array = cv2.imread(os.path.join(path,img))\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "                image_std = new_array.astype('float') / 255.0\n",
    "                training_data.append([image_std, class_num])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "create_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2688bdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a testing data set\n",
    "testing_data = []\n",
    "\n",
    "def create_testing_data():\n",
    "    for category in CATEGORIES:\n",
    "        test_path = os.path.join(test_dir, category) # path to cats or dogs directory\n",
    "        class_num = CATEGORIES.index(category)\n",
    "        for img in os.listdir(test_path):\n",
    "            # using try and except to pass all the images that have problem in resizeing\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(test_path,img))\n",
    "                test_new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "                image_std = test_new_array.astype('float') / 255.0\n",
    "                testing_data.append([image_std, class_num])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "create_testing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d775a0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2dee9245",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = []\n",
    "train_label = []\n",
    "test_features = []\n",
    "test_label = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c99d0c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# breaking trainig_data and testing_data into features and label and turning into numoy array.\n",
    "train_features = np.array([i[0] for i in training_data]).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
    "test_features = np.array([i[0] for i in testing_data]).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
    "test_label = np.array([i[1] for i in testing_data])\n",
    "train_label = np.array([i[1] for i in training_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e012e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "opt_1 = Adam(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c295c80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "251/251 [==============================] - 43s 159ms/step - loss: 0.6815 - accuracy: 0.5631 - val_loss: 0.6672 - val_accuracy: 0.5885\n",
      "Epoch 2/5\n",
      "251/251 [==============================] - 34s 135ms/step - loss: 0.6005 - accuracy: 0.6802 - val_loss: 0.5660 - val_accuracy: 0.7190\n",
      "Epoch 3/5\n",
      "251/251 [==============================] - 33s 130ms/step - loss: 0.5354 - accuracy: 0.7334 - val_loss: 0.5618 - val_accuracy: 0.7125\n",
      "Epoch 4/5\n",
      "251/251 [==============================] - 29s 116ms/step - loss: 0.4798 - accuracy: 0.7707 - val_loss: 0.5067 - val_accuracy: 0.7550\n",
      "Epoch 5/5\n",
      "251/251 [==============================] - 35s 139ms/step - loss: 0.4329 - accuracy: 0.8017 - val_loss: 0.5006 - val_accuracy: 0.7705\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x224efc3ec10>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the model and adding hyperparameters to have better accuracy\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (3,3), input_shape = train_features.shape[1:]))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, (3,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten()) # this convert our 3D features map into 1D vectors\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "             optimizer = opt_1,\n",
    "             metrics = [\"accuracy\"])\n",
    "\n",
    "model.fit(train_features, train_label, batch_size=32, epochs= 5, validation_data =(test_features, test_label), callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7023c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
