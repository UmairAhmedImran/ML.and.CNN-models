{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d77c311c",
   "metadata": {},
   "source": [
    "## PART A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e03dde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all necessary libraries\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.regularizers import L2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff15b291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definig some variables\n",
    "IMG_SIZE = 50\n",
    "DATADIR = \"C:/Assignment_images\"\n",
    "test_dir = \"C:/test_set\"\n",
    "CATEGORIES = [\"cats\", \"dogs\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598ab05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a training data set\n",
    "training_data = []\n",
    "def create_training_data():\n",
    "    for category in CATEGORIES:\n",
    "        path = os.path.join(DATADIR, category) # path to cats or dogs directory\n",
    "        class_num = CATEGORIES.index(category)\n",
    "        \n",
    "        for img in os.listdir(path):\n",
    "            # using try and except to pass all the images that have problem in resizeing\n",
    "            try: \n",
    "                img_array = cv2.imread(os.path.join(path,img))\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "                image_std = new_array.astype('float') / 255.0\n",
    "                training_data.append([image_std, class_num])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "create_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2688bdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a testing data set\n",
    "testing_data = []\n",
    "\n",
    "def create_testing_data():\n",
    "    for category in CATEGORIES:\n",
    "        test_path = os.path.join(test_dir, category) # path to cats or dogs directory\n",
    "        class_num = CATEGORIES.index(category)\n",
    "        for img in os.listdir(test_path):\n",
    "            # using try and except to pass all the images that have problem in resizeing\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(test_path,img))\n",
    "                test_new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "                image_std = test_new_array.astype('float') / 255.0\n",
    "                testing_data.append([image_std, class_num])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "create_testing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d775a0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dee9245",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = []\n",
    "train_label = []\n",
    "test_features = []\n",
    "test_label = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99d0c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = np.array([i[0] for i in training_data]).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
    "test_features = np.array([i[0] for i in testing_data]).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
    "test_label = np.array([i[1] for i in testing_data])\n",
    "train_label = np.array([i[1] for i in training_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e012e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "opt_1 = Adam(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c295c80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the model and adding hyperparameters to have better accuracy\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (3,3), input_shape = train_features.shape[1:]))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, (3,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten()) # this convert our 3D features map into 1D vectors\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "             optimizer = opt_1,\n",
    "             metrics = [\"accuracy\"])\n",
    "\n",
    "history = model.fit(train_features, train_label, batch_size=32, epochs= 10, validation_data =(test_features, test_label))\n",
    "model.save('2_000.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314b1dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot function to plot some basic relationship between columns\n",
    "def plotter(history_file):\n",
    "    with open(history_file, 'rb') as file:\n",
    "        history = pickle.load(file)\n",
    "    \n",
    "    plt.plot(history['accuracy'])\n",
    "    plt.plot(history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    plt.savefig('2_000_10epoch_accuracy.png')\n",
    "\n",
    "    plt.plot(history['loss'])\n",
    "    plt.plot(history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()\n",
    "    plt.savefig('2_000_10epoch_loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686e95df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "history_file = '2_000_history.pickle'\n",
    "with open(history_file, 'wb') as file:\n",
    "    pickle.dump(history.history, file)\n",
    "\n",
    "plotter(history_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35b482d",
   "metadata": {},
   "source": [
    "## PART B "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275a1959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import preprocessing, svm, metrics  \n",
    "import math\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1f4623",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"Downloads/cw3_housing_data_part_b.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e72d114",
   "metadata": {},
   "source": [
    "### Visualization and description of data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d77c77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75177193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create arrays for features and target variable\n",
    "y = df['price'].values\n",
    "X = df['sqft_living15'].values\n",
    "\n",
    "# Print the dimensions of X and y before reshaping\n",
    "print(\"Dimensions of y before reshaping: {}\".format(y.shape))\n",
    "print(\"Dimensions of X before reshaping: {}\".format(X.shape))\n",
    "\n",
    "# Reshape X and y\n",
    "y = y.reshape(-1, 1)\n",
    "X = X.reshape(-1, 1)\n",
    "\n",
    "# Print the dimensions of X and y after reshaping\n",
    "print(\"Dimensions of y after reshaping: {}\".format(y.shape))\n",
    "print(\"Dimensions of X after reshaping: {}\".format(X.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5581be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.corr(), square=True, cmap='RdYlGn')\n",
    "plt.xticks(rotation=90)\n",
    "plt.yticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69220e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c582728",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63ce37a",
   "metadata": {},
   "source": [
    "### LINEAR REGRESSION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b34b68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['price'].values\n",
    "X = df.drop('price', axis=1)\n",
    "\n",
    "# Reshape to 1-D\n",
    "y = y.reshape(-1, 1)\n",
    "X_sqft_living = X['sqft_living'].values.reshape(-1, 1) \n",
    "\n",
    "_ = plt.scatter(X['sqft_living'], y, color='blue')\n",
    "_ = plt.ylabel('Price Expectancy')\n",
    "_ = plt.xlabel('Sqft_living')\n",
    "\n",
    "# -----------------------\n",
    "# Import LinearRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create the regressor: reg\n",
    "reg = LinearRegression()\n",
    "\n",
    "# Create the prediction space\n",
    "prediction_space = np.linspace(min(X_sqft_living), max(X_sqft_living)).reshape(-1,1)\n",
    "\n",
    "# Fit the model to the data\n",
    "reg.fit(X_sqft_living, y)\n",
    "\n",
    "# Compute predictions over the prediction space: y_pred\n",
    "y_pred = reg.predict(prediction_space)\n",
    "\n",
    "# Print R^2 \n",
    "print(reg.score(X_sqft_living, y))\n",
    "\n",
    "# Plot regression line\n",
    "plt.plot(prediction_space, y_pred, color='black', linewidth=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98628b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42)\n",
    "\n",
    "# Create the regressor: reg_all\n",
    "reg_all = LinearRegression()\n",
    "\n",
    "# Fit the regressor to the training data\n",
    "reg_all.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data: y_pred\n",
    "y_pred = reg_all.predict(X_test)\n",
    "\n",
    "# Compute and print R^2 and RMSE\n",
    "print(\"R^2: {}\".format(reg_all.score(X_test, y_test)))\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Root Mean Squared Error: {}\".format(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4b2a88",
   "metadata": {},
   "source": [
    "### DECISION TREE REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228572b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['bedrooms','bathrooms', 'sqft_living', 'view', 'condition']].values\n",
    "y = df['price'].values\n",
    "\n",
    "(X_train, X_test, y_train, y_test) = train_test_split(X, y, train_size=0.7, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9449e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(X_train, y_train)\n",
    "dtc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac0de2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_gini = DecisionTreeClassifier(criterion = \"gini\", random_state = 100,\n",
    "                               max_depth=3, min_samples_leaf=5)\n",
    "clf_gini.fit(X_train, y_train)\n",
    "\n",
    "clf_entropy = DecisionTreeClassifier(criterion = \"entropy\", random_state = 100,\n",
    "max_depth=3, min_samples_leaf=5)\n",
    "clf_entropy.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd17262b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf_gini.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd58888e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Accuracy is :\", accuracy_score(y_test,y_pred)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab428fcc",
   "metadata": {},
   "source": [
    "### RANDOM FOREST REGRESSION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e48ff2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['bedrooms','bathrooms', 'sqft_living', 'view', 'condition']\n",
    "t_val_subset = df[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600b7aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test =  train_test_split(X, y, test_size=0.20, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ca81bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestRegressor(n_estimators = 3000, random_state = 10)\n",
    "# Train the model on training data\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08980757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the forest's predict method on the test data\n",
    "prediction_s = clf.predict(X_test)\n",
    "# Calculate the absolute errors\n",
    "errors_s = abs(prediction_s - y_test)\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error:', round(np.mean(errors_s), 2), 'degrees.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6414df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean absolute percentage error (MAPE)\n",
    "mape = 100 * (errors_s - y_test)\n",
    "# Calculate and display accuracy\n",
    "accuracy = 100 - np.mean(mape)\n",
    "print('Accuracy:', round(accuracy, 2), '%.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b3eb78",
   "metadata": {},
   "source": [
    "### SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722a38ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_linear = SVR(kernel='linear',gamma='scale', C=1.0, epsilon=0.1)\n",
    "svr_linear.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d529bd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_linear.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b96254",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = LinearRegression()\n",
    "linear.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6730867",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d7287d",
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_rbf = SVR(kernel='rbf',gamma='scale', C=1.0, epsilon=0.1)\n",
    "svr_rbf.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f16311e",
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_rbf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f59e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RMSE for linear SVR:\",np.sqrt(mean_squared_error(y_test,svr_linear.predict(X_test))))\n",
    "print(\"RMSE for RBF kernelized SVR:\",np.sqrt(mean_squared_error(y_test,svr_rbf.predict(X_test))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
